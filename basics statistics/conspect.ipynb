{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------\n",
    "# Основы статистики I\n",
    "-------------------------------------------------------------------------------\n",
    "## 1. Введение\n",
    "\n",
    "\n",
    "### 1.1. Генеральная совокупность и выборка\n",
    "\n",
    "Хотим, чтобы **выборка** (sample) была репрезентативна **генеральной совокупности** (population) (т.е. отражала её свойства). Есть несколько способов этого добиться:\n",
    "\n",
    "1. **Простая случайная выборка** (simple random sample).\n",
    "2. **Стратифицированная выборка** (stratified sample).\n",
    "    Генеральная совокупность разбивается на несколько разнородных групп (например, население по полу, возрасту и т.д.), а затем уже из каждой группы случайно выбираются элементы. \n",
    "3. **Групповая выборка** (cluster sample).\n",
    "    Генеральная совокупность разбивается на несколько групп схожего состава (например, население города по районам), а затем случайная выборка берётся только из нескольких групп (кластеров).\n",
    "\n",
    "Нас интересуют характеристики генеральной совокупности, которые мы исследуем с помощью выборки.\n",
    "\n",
    "Типы переменных:\n",
    "\n",
    "1. **Количественные** (numerical): порядок и метрика.\n",
    "    - непрерывные\n",
    "    - дискретные\n",
    "2. **Порядковые**, или ранговые (ordinal): порядок без метрики.\n",
    "3. **Категориальные**, или номинативные (categorical): ни метрики, ни порядка.\n",
    "\n",
    "\n",
    "### 1.2. Меры центральной тенденции\n",
    "\n",
    "Для исследования распределений изучаемых признаков элементов генеральной совокупности строят **гистограммы частот**. Если распределение асимметрично или есть большие выбросы, то вместо среднего лучше использовать моду и медиану:\n",
    "\n",
    "**Мода** (mode) — значение признака, которое встречается максимально часто.\n",
    "\n",
    "**Медиана** (median) — значение признака, которое делит упорядоченное множество данных пополам.\n",
    "\n",
    "Свойства среднего значения:\n",
    "\n",
    "1. $M_{x + C} = M_x + C \\,,$\n",
    "2. $M_{C x} = C \\, M_x \\,,$\n",
    "3. $\\sum_i \\left( x_i - M_x \\right) = 0 \\,.$\n",
    "\n",
    "\n",
    "### 1.3. Меры изменчивости\n",
    "\n",
    "**Размах** (range) — разность максимального и минимального значения.\n",
    "\n",
    "$$\n",
    "R = x_{max} - x_{min}\\,.\n",
    "$$\n",
    "\n",
    "**Дисперсия** (variance) — средний квадрат отклонений значений признака от их средней величины.\n",
    "\n",
    "$$\n",
    "D = \\dfrac{\\sum_i \\left( x_i - \\bar{x} \\right)^2}{n} \\quad \\text{ для генеральной совокупности,} \\\\\n",
    "D_x = \\dfrac{\\sum_i \\left( x_i - \\bar{x} \\right)^2}{n - 1} \\quad \\text{ для выборки.}\n",
    "$$\n",
    "\n",
    "**Стандартное отклонение** (standard deviation) — среднее отклонение индивидуальных значений признака от их средней величины.\n",
    "\n",
    "$$\n",
    "\\sigma = \\sqrt{D} \\quad \\text{ для генеральной совокупности,} \\\\\n",
    "s_x = \\sqrt{D} \\quad \\text{ для выборки.}\n",
    "$$\n",
    "\n",
    "Свойства дисперсии и стандартного отклонения:\n",
    "\n",
    "1. $D_{x + C} = D_x \\,,$\n",
    "2. $D_{C x} = C^2 D_x \\,,$\n",
    "3. $s_{x + C} = s_x \\,,$\n",
    "4. $s_{C x} = |C| s_x \\,.$\n",
    "\n",
    "\n",
    "### 1.4. Квантили распределения\n",
    "\n",
    "**Квантили** — значения признака, которые делят упорядоченные данные на некоторое число равных частей (например, медиана или квартили).\n",
    "\n",
    "**Квартили** — три значения признака, которые делят данные на четыре равные части.\n",
    "\n",
    "Используя квартили можно построить **box-plot**: коробка, где центр — медиана (второй квартиль), верхная граница — третий квартиль, нижняя — первый. Плюс две линии с максимальной длиной в 1.5 межквартильного размаха вверх и вниз, а также отдельные точки на краях распределения (если не попали в коробку).\n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"data/box-plot.png\" width=\"500\" title=\"box-plot\"></p>\n",
    "\n",
    "\n",
    "### 1.5. Нормальное распределение\n",
    "\n",
    "$$\n",
    "f(x) = \\dfrac{1}{\\sqrt{2 \\pi} \\sigma} \\, \\exp \\left(-\\dfrac{\\left(x - \\mu\\right)^2}{2 \\sigma^2}\\right)\\,.\n",
    "$$\n",
    "\n",
    "Свойства нормального распределения:\n",
    "\n",
    "- унимодальность\n",
    "- симметричность\n",
    "- \"правило трёх сигм\"\n",
    "- центральная предельная теорема (средние значения для набора случайных выборок из данной генеральной совокупности распределены нормально с характеристиками $\\bar{x}$ и $s_{\\bar{x}}$).\n",
    "\n",
    "$$\n",
    "\\bar{x} = \\mu \\,, \\qquad s_{\\bar{x}} = \\dfrac{\\sigma}{\\sqrt{n}} \\, \\stackrel{n > 30}{\\approx} \\, \\dfrac{s_x}{\\sqrt{n}}.\n",
    "$$\n",
    "\n",
    "**Стандартизация** (Z-преобразование) – преобразование данных в стандартную шкалу (standard score) с характеристиками $M_z = 0$ и $D_z = 1$.\n",
    "\n",
    "$$\n",
    "Z_i = \\dfrac{x_i - \\bar{x}}{s_x} \\,.\n",
    "$$\n",
    "\n",
    "\n",
    "### 1.6. Доверительные интервалы\n",
    "\n",
    "Центральная предельная теорема позволяет по полученным значениям признаков конкретной выборки делать выводы о значениях этих признаков для генеральной совокупности с определёнными **доверительными интервалами** (confidence intervals).\n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"data/confidence_interval.PNG\" width=\"500\" title=\"confidence interval\"></p>\n",
    "\n",
    "Например, что для генеральной совокупности $\\mu = \\bar{x} \\pm m \\, s_{\\bar{x}}$. Здесь, $m$ — коэффициент, определяемый из требуемой уверенности предсказаний.\n",
    "\n",
    "| Интервал | Доля внутри интервала |\n",
    "|:--------:|:---------------------:|\n",
    "|   μ ± σ  |  0.682689 492 137 086 |\n",
    "|  μ ± 2σ  |  0.954499 736 103 642 |\n",
    "|  μ ± 3σ  |  0.997300 203 936 740 |\n",
    "|  μ ± 4σ  |  0.999936 657 516 334 |\n",
    "|  μ ± 5σ  |  0.999999 426 696 856 |\n",
    "\n",
    "\n",
    "### 1.7. Проверка гипотез\n",
    "\n",
    "$H_0$ — нулевая гипотеза, $H_1$ — альтернативная гипотеза.\n",
    "\n",
    "0. Допустить, что верна $H_0$, т.е. никаких различий значений признаков между выборкой и генеральной совокупностью нет.  \n",
    "1. Рассчитать вероятность получить наблюдаемые (или большие) различия случайно при условии верности $H_0$ (**p-уровень значимости** или p-value).  \n",
    "2. На основании уровня значимости, принять решение о состоятельности $H_0$.  \n",
    "\n",
    "Пусть известно $\\mu$ — среднее значение генеральной совокупности, а также получены значения $\\bar{x}$ и $s_{x}$ для некоторой выборки из $N$ элементов. Тогда $H_0$ — различия между $\\mu$ и $\\bar{x}$ случайны и истинное значение среднего для генеральной совокупности равно $\\mu$.\n",
    "\n",
    "Чтобы посчитать уровень значимости для $H_0$ сначала найдём $s_{\\bar{x}}$ и посмотрим на сколько среднее выборки $\\bar{x}$ отклоняется от среднего генеральной совокупности $\\mu$ в единицах стандартного отклонения среднего $s_{\\bar{x}}$.\n",
    "\n",
    "$$\n",
    "s_{\\bar{x}} = \\dfrac{s_x}{\\sqrt{N}} \\,, \\qquad Z_{\\bar{x}} = \\dfrac{\\bar{x} - \\mu}{s_{\\bar{x}}}.\n",
    "$$\n",
    "\n",
    "Получив $Z_{\\bar{x}}$, найдём вероятность получить значение в интервале $|Z| > Z_{\\bar{x}}$ :\n",
    "\n",
    "$$\n",
    "p \\left( |Z| > Z_{\\bar{x}} \\right) = \\int\\limits_{- \\infty}^{Z_{\\bar{x}}} f(Z) \\, dZ + \\int\\limits_{Z_{\\bar{x}}}^{+ \\infty} f(Z) \\, dZ \\,.\n",
    "$$\n",
    "\n",
    "Тогда $p$ — вероятность того, что значение $\\bar{x}$ (или ещё больше отличающееся от $\\mu$) случайно, при предположении, что $\\mu$ — среднее значение генеральной совокупности (т.е. верности $H_0$).\n",
    "\n",
    "Подробней про [уровни значимости](https://habr.com/en/company/stepic/blog/250527/).\n",
    "\n",
    "1. Уровень значимости — это **НЕ** вероятность верности нулевой гипотезы.\n",
    "    $$\n",
    "    p(observation | hypothesis) \\neq p(hypothesis | observation).\n",
    "    $$\n",
    "2. Если уровень значимости слишком большой, то вывод: недостаточно оснований для отклонения $H_0$.\n",
    "3. Уровень значимости ничего не говорит ни о правильности, ни о научности результатов.\n",
    "\n",
    "**Статистические ошибки**:\n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"data/typeI_typeII.jpg\" width=\"500\" title=\"stat errors\"></p>\n",
    "\n",
    "1. Отклонили $H_0$, хотя она верна (**ложно-положительная**).\n",
    "2. Не отклонили $H_0$, хотя она неверна (**ложно-отрицательная**).\n",
    "\n",
    "\n",
    "-------------------------------------------------------------------------------\n",
    "## 2. Сравнение средних\n",
    "\n",
    "\n",
    "### 2.1. Распределение Стьюдента\n",
    "\n",
    "Из центральной предельной теоремы знаем, что средние значения для выборок из генеральной совокупности распределятся нормально вокруг среднего генеральной совокупности:\n",
    "\n",
    "$$\n",
    "Z = \\frac{\\bar{x} - \\mu}{\\frac{\\sigma}{\\sqrt{n}}} \\,.\n",
    "$$\n",
    "\n",
    "Однако, на практике стандартное отклонение генеральной совокупности $\\sigma$ почти всегда неизвестно, поэтому используют стандартное отклонение выборки $s_x$, но тогда распределение будет уже не нормальным. Это и будет **распределение Стьюдента** (t-distribution). Оно похоже на нормальное (унимодально и симметрично), но слабее прижато к среднему значению (зависит от числа степеней свободы $\\nu$).\n",
    "\n",
    "$$\n",
    "t = \\frac{\\bar{x} - \\mu}{\\frac{s_x}{\\sqrt{n}}} \\,.\n",
    "$$\n",
    "\n",
    "Форма распределения определяется числом степеней свободы ($\\nu = n - 1$). Чем больше $\\nu$, тем распределение ближе к нормальному.\n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"data/t df.png\" width=\"450\" title=\"degrees of freedom\"></p>\n",
    "\n",
    "Если $n > 30$, то часто из соображений удобства вместо t-распределения используют нормальное распределение, хотя это всё таки не верно. Поэтому следует использовать t-распределение при проверке гипотез и расчёте доверительных интервалов (!).\n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"data/t-dist vs normal.png\" width=\"400\" title=\"t-dist vs normal\"></p>\n",
    "\n",
    "\n",
    "### 2.2. Сравнение двух средних\n",
    "\n",
    "**t-критерий Стьюдента** (парный t-тест) — критерий, позволяющий сравнивать две выборки между собой.\n",
    "\n",
    "- Допустим даны две выборки $X_1$ и $X_2$ и хотим проверить взяты ли они из одной генеральной совокупности (нулевая гипотеза). Для этого найдём вероятность получить данные выборки, при условии верности $H_0$, т.е. что $\\mu_1 = \\mu_2$.\n",
    "\n",
    "- Если извлекать выборки $X_1$ и $X_2$ много раз, то величина $\\bar{x_1} - \\bar{x_2}$ будет иметь t-распределение с $\\nu = n_1 + n_2 - 2$\n",
    "\n",
    "    $$\n",
    "    t = \\dfrac{\\left( \\bar{x}_1 - \\bar{x}_2 \\right) - \\left( \\mu_1 - \\mu_2 \\right)}{\\sqrt{\\frac{s_{X_1}^2}{n_1} + \\frac{s_{X_1}^2}{n_2}}} \\, \\stackrel{H_0}{=} \\, \\dfrac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{\\frac{s_{X_1}^2}{n_1} + \\frac{s_{X_1}^2}{n_2}}} \\,.\n",
    "    $$\n",
    "\n",
    "- Посчитав $t$ можно найти уровень значимости $H_0$ (p-value) при данных значениях $\\bar{x_1}$ и $\\bar{x_2}$.\n",
    "\n",
    "Требования на использование t-критерия:\n",
    "\n",
    "1. Дисперсии $X_1$ и $X_2$ должны быть близки (гомогенность дисперсий). Это можно проверить используя критерий Левена (Levene's test) или критерий Фишера.\n",
    "2. Если объём выборок небольшой, то важно, чтобы они были нормально распределены.\n",
    "\n",
    "**Примеры**:\n",
    "\n",
    "1. Первая выборка — это пациенты, которых лечили препаратом А. Вторая выборка — пациенты, которых лечили препаратом Б. Значения в выборках — это некоторая характеристика эффективности лечения (уровень метаболита в крови, температура через три дня после начала лечения, срок выздоровления, число койко-дней, и т.д.) Требуется выяснить, имеется ли значимое различие эффективности препаратов А и Б, или различия являются чисто случайными и объясняются «естественной» дисперсией выбранной характеристики.\n",
    "\n",
    "2. Первая выборка — это значения некоторой характеристики состояния пациентов, записанные до лечения. Вторая выборка — это значения той же характеристики состояния тех же пациентов, записанные после лечения. Объёмы обеих выборок обязаны совпадать; более того, порядок элементов (в данном случае пациентов) в выборках также обязан совпадать. Такие выборки называются связными. Требуется выяснить, имеется ли значимое отличие в состоянии пациентов до и после лечения, или различия чисто случайны.\n",
    "\n",
    "3. Первая выборка — это поля, обработанные агротехническим методом А. Вторая выборка — поля, обработанные агротехническим методом Б. Значения в выборках — это урожайность. Требуется выяснить, является ли один из методов эффективнее другого, или различия урожайности обусловлены случайными факторами.\n",
    "\n",
    "4. Первая выборка — это дни, когда в супермаркете проходила промо-акция типа А (красные ценники со скидкой). Вторая выборка — дни промо-акции типа Б (каждая пятая пачка бесплатно). Значения в выборках — это показатель эффективности промо-акции (объём продаж, либо выручка в рублях). Требуется выяснить, какой из типов промо-акции более эффективен.\n",
    "\n",
    "\n",
    "### 2.3. Проверка на нормальность\n",
    "\n",
    "Для проверки распределения выборки на нормальность (или в общем случае на соответствие любому распределению) часто используют **QQ plot** (quantile-quantile plot).\n",
    "\n",
    "Для этого разделяют выборку и теоретическое распределение $n$ квантилями (где $n$ — число измерений в выборке), и строят набор $n + 1$ точек $(q_{theory}^i, q_{sample}^i)$. Если распределение в выборке нормально, то все точки лягут на диагональную прямую.\n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"data/QQPlot.png\" width=\"400\" title=\"QQ plot\"></p>\n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"data/QQ_plots.PNG\" width=\"800\" title=\"QQ plots\"></p>\n",
    "\n",
    "- Если нужно сравнить распределения двух выборок, то процесс аналогичный, только берут число квантилей, соответствующее выборке с наименьшим числом данных.\n",
    "\n",
    "- Кроме QQ графиков для проверки на нормальность также используют **тест Колмогорова-Смирнова** и **тест Шапиро-Уилка**.\n",
    "\n",
    "- Отклонения от нормальности может негативно повлиять на результаты исследований, например когда в выборке появляются большие выбросы. Чтобы избежать их влияния, например, вместо t-критерия используют его непараметрический аналог **U-тест Манна-Уитни** (переводит данные в ранговую шкалу).\n",
    "\n",
    "\n",
    "### 2.4. Однофакторный дисперсионный анализ (one-way ANOVA)\n",
    "\n",
    "Часто в исследованиях возникает необходимость сравнить несколько групп между собой, в таком случае применяют **однофакторный дисперсионный анализ**. Категориальная переменная, которая будет разделять наблюдения на группы называется независимой переменной, а та количественная переменная, по степени выраженности которой мы сравниваем группы, называется зависимой переменной.\n",
    "\n",
    "**Условия применимости**:\n",
    "\n",
    "- нормальность распределения зависимой переменной в каждой из групп (проверить с помощью QQ plot или тестом Шапиро-Уилка)\n",
    "\n",
    "- гомогенность дисперсий в группах (проверить тестом Левена или другими критериями)\n",
    "\n",
    "- при большом числе измерений дисперсионный анализ устойчив к нарушению обоих вышеизложенных требований\n",
    "\n",
    "Пусть выборка разделена на $m$ групп, а $H_0$ — все различия между группами случайны и в генеральной совокупности $\\mu_1 = \\cdots = \\mu_m$ (альтернатива — хотя бы две группы различаются). Для анализа групп рассчитаем следующие характеристики:\n",
    "\n",
    "1. Общую сумму квадратов (**sum squared total**) $SST = \\sum_{i = 1}^{N} \\left( x_i - \\bar{x} \\right)^2$  и число степеней свободы всей выборки $df_{total} = N - 1$.\n",
    "\n",
    "2. Внутригрупповую сумму квадратов (**within**) $SSW = \\sum_{j = 1}^{m} \\sum_{i = 1}^{n_j} \\left( x_i^{(j)} - \\bar{x}^{(j)} \\right)^2$ и внутригрупповое число степеней свободы $df_{wg} = N - m$.\n",
    "\n",
    "3. Межгрупповую сумму квадратов (**between**) $SSВ = \\sum_{j = 1}^{m} n_j \\, \\left( \\bar{x}^{(j)} - \\bar{x} \\right)^2$ и межгрупповое число степеней свободы $df_{bg} = m - 1$.\n",
    "\n",
    "$$\n",
    "SST = SSW + SSB \\,, \\qquad df_{total} = df_{wg} + df_{bg} \\,.\n",
    "$$\n",
    "\n",
    "Т.е. если большая часть $SST$ происходит из $SSB$, то это намекает на то, что группы различны между собой. Для количественной оценки используют **F-значение** (чем больше, тем вероятней различие между группами):\n",
    "\n",
    "$$\n",
    "F = \\dfrac{SSB / df_{bg}}{SSW / df_{wg}} = \\dfrac{MS_{bg}}{MS_{wg}} \\,.\n",
    "$$\n",
    "\n",
    "Для расчета вероятности получить такие (или ещё более сильные) различия случайно при условии верности $H_0$ нужно подставить полученное значение $F$ в распределение Фишера и посчитать интеграл\n",
    "\n",
    "$$\n",
    "p \\left( F' > F \\right) = \\int\\limits_{F}^{+ \\infty} f(df_{bg}, df_{wg}, F') \\, dF' \\,.\n",
    "$$\n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"data/F_pdf.png\" width=\"500\" title=\"Fisher distribution\"></p>\n",
    "\n",
    "**Пример**:\n",
    "\n",
    "Сравнивается 4 типа генотерапии и их эффективность:\n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"data/Mathematica 01.PNG\" width=\"800\" title=\"Mathematica 01\"></p>\n",
    "\n",
    "Вывод: наличие различия между группами статистически достоверно, однако пока **нельзя** сделать вывод между какими именно группами оно есть.\n",
    "\n",
    "\n",
    "### 2.5. Множественные сравнения\n",
    "\n",
    "Если многократно извлекать из генеральной совокупности выборки из $m$ групп по $n$ элементов в каждой группе, а затем проверять с помощью t-критерия есть ли основания полагать, что между хотя бы какими-то двумя группами в выборке есть статистически значимые различия, то окажется, что вероятность получить положительный ответ на этот вопрос чисто случайно (совершить ошибку $I$-ого рода) стремится к единице при увеличении $n$ и $m$.  \n",
    "\n",
    "Для корректировки результата нужно изменить используемый уровень значимости, в соответствии с количеством групп $m$ (**поправки на множественное сравнение**).\n",
    "\n",
    "1. **Поправка Бонферони** (Bonferroni correction).\n",
    "\n",
    "    Разделить p-value на количество парных сравнений (очень консервативный показатель), т.е.\n",
    "\n",
    "    $$\n",
    "    p_m = \\dfrac{p_0}{N_{m}} \\quad \\,, \\text{где} \\, N_{m} = \\binom{m}{2} = \\dfrac{m \\, (m -1)}{2} \\,.\n",
    "    $$\n",
    "\n",
    "2. **Поправка Тьюки** (Tukey correction).\n",
    "\n",
    "    Критерий Тьюки для оценки различия между группами:\n",
    "\n",
    "    $$\n",
    "    q_{i j} = \\frac{\\overline x_i - \\overline x_j}{SE_{i j}}, \\quad  {SE}_{i j} = \\displaystyle\\sqrt{\\frac{MSW_{ij}}{2}\\left (\\frac{1}{n_i}+\\frac{1}{n_j}\\right )} \\,.\n",
    "    $$\n",
    "\n",
    "    Доверительный интервал же рассчитывается с помощью [Studentized range distribution](https://en.wikipedia.org/wiki/Studentized_range_distribution).\n",
    "\n",
    "**Пример**:\n",
    "\n",
    "Пример про генотерапию из прошлого параграфа:\n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"data/tukey.PNG\" width=\"800\" title=\"Tukey test\"></p>\n",
    "\n",
    "Можно сделать вывод, что статистически достоверно отличаются между собой только группы C и A, D и A, D и B (доверительные интервал для разности их средних не включает в себя ноль).\n",
    "\n",
    "- Если не использовать поправки на множественное сравнение, то очень легко делать неверные выводы: [Статистика и плохая наука — Александр Панчин](https://www.youtube.com/watch?v=7To5LPZ9mxc).\n",
    "\n",
    "- Любые данные можно дообрабатывать до такой степени, чтобы найти в них, что угодно, поэтому стоит формулировать проверяемые гипотезы до эксперимента. Однако, это не значит, что не нужно искать новые закономерности во время обработки данных (а затем проводить новые эксперименты).\n",
    "\n",
    "\n",
    "### 2.6. Многофакторный дисперсионный анализ (n-way ANOVA)\n",
    "\n",
    "Аналогичен однофакторному, только теперь есть несколько независимых категориальных переменных (т.е. несколько признаков разделения выборки на группы). При этом также следует проверять **взаимодействие факторов** между собой (влияние одного фактора на зависимую переменную может по-разному проявляться в зависимости от значения другого фактора). \n",
    "\n",
    "Например, для двух факторов $SST = SSW + SSB_A + SSB_B + SSB_A \\, SSB_B$.\n",
    "\n",
    "**Пример**:\n",
    "\n",
    "1. Компания, разрабатывающая мобильные телефоны, перед выпуском двух новых моделей, решила выяснить, как потенциальные пользователи воспринимают эти новинки. Для этого компания набрала фокус-группу (100 мужчин, 100 женщин) и попросила участников оценить дизайн новых моделей телефонов от 1 до 100. Чтобы проанализировать полученные результаты, был применен двуфакторный дисперсионный анализ (зависимая переменная — оценка испытуемых по 100-балльной шкале, независимые переменные (факторы) — номер модели и пол испытуемых). \n",
    "\n",
    "    <p style=\"text-align:center;\"><img src=\"data/two-way_anova_example.PNG\" width=\"800\" title=\"2-way ANOVA\"></p>\n",
    "\n",
    "    A — значимый эффект только для фактора модели телефона, B — значимый эффект только для фактора пола участников исследования, C — значимый эффект для обоих факторов, D — значимое взаимодействие факторов.\n",
    "\n",
    "2. Влияние инъекции некоторого гормона на концентрацию кальция в плазме крови у птиц с учётом пола.\n",
    "\n",
    "    <p style=\"text-align:center;\"><img src=\"data/Mathematica 02.PNG\" width=\"800\" title=\"Mathematica 02\"></p>\n",
    "\n",
    "    Получилось, что ни фактор пола, ни фактор гормона по отдельности не оказывают значимого влияния на зависимую переменную, однако их взаимодействие — оказывает.\n",
    "\n",
    "\n",
    "-------------------------------------------------------------------------------\n",
    "## 3. Корреляция и регрессия\n",
    "\n",
    "\n",
    "### 3.1. Корреляция\n",
    "\n",
    "**Корреляция** — взаимосвязь двух количественных переменных.\n",
    "\n",
    "Качественно наличие взаимосвязи можно увидеть с помощью **ковариации**, а количественно оценить степень и направление взаимосвязи позволяет **коэффициент корреляции** (Пирсона).\n",
    "\n",
    "$$\n",
    "\\mathrm{cov}\\left( X, Y \\right) = \\dfrac{\\sum_i \\left( X_i - \\bar{X} \\right) \\left( Y_i - \\bar{Y} \\right)}{N - 1} = \\bar{X Y} - \\bar{X} \\bar{Y} \\,, \\\\\n",
    "r_{X Y} = \\dfrac{\\mathrm{cov}\\left( X, Y \\right)}{\\sigma_{X}\\sigma_{Y}} = \\dfrac{\\bar{X Y} - \\bar{X} \\bar{Y}}{ \\sqrt{\\sum_i(X_i - \\bar{X})^2\\sum_i(Y_i - \\bar{Y})^2}} \\,.\n",
    "$$\n",
    "\n",
    "- $r_{X Y} \\in [-1, 1]$.\n",
    "\n",
    "- большой коэффициент корреляции не обязательно означает статистически значимую взаимосвязь (например, при малом числе наблюдений значение $r_{X Y}$ велико).\n",
    "\n",
    "- корреляция $\\neq$ причинно-следственная связь (хотя может быть аргументом в её пользу).\n",
    "\n",
    "    - Николас Кейдж и число утонувших в бассейне\n",
    "\n",
    "        <p style=\"text-align:center;\"><img src=\"data/cor_cause.png\" width=\"650\" title=\"causation\"></p>\n",
    "\n",
    "    - Исследование показало, что чем больше пожарных расчетов выезжает на пожар, тем больше от него ущерб.\n",
    "\n",
    "- коэффициент корреляции Пирсона работает только в случае монотонной линейной связи.\n",
    "\n",
    "    <p style=\"text-align:center;\"><img src=\"data/cor_fail.PNG\" width=\"700\" title=\"correlation fail 1\"></p>\n",
    "\n",
    "- требуется нормальное распределение исследуемых переменных (большие выбросы, бимодальность, асимметрия плохо сказываются на значении коэффициента корреляции, делая его бесполезным). Однако у коэффициента Пирсона есть непараметрические (ранговые) аналоги — **коэффициент корреляции Спирмена** и **коэффициент корреляции $\\tau$-Кендалла**.\n",
    "\n",
    "    <p style=\"text-align:center;\"><img src=\"data/cor_fail2.PNG\" width=\"650\" title=\"correlation fail 2\"></p>\n",
    "\n",
    "\n",
    "### 3.2. Простая линейная регрессия\n",
    "\n",
    "**Регрессионный анализ** — совокупность методов позволяющих исследовать взаимосвязь исследуемых переменных между собой.\n",
    "\n",
    "**МНК** — один из способов нахождения оптимальных параметров линейной регрессии (минимизируется сумма квадратов ошибок $\\sum_i e^2_i = \\sum_i \\left( y_i - \\hat{y_i} \\right)^2$, см. численные методы).\n",
    "\n",
    "Одномерная линейная регрессия:\n",
    "\n",
    "$$\n",
    "\\hat{y} = b_0 + b_1 \\,x \\,, \\text{где} \\quad \\begin{matrix} b_1 = \\dfrac{s_y}{s_x} \\, r_{x y} \\,, \\\\ b_0 = \\bar{y} - b_1 \\bar{x} \\,. \\end{matrix}\n",
    "$$\n",
    "\n",
    "**Значимость взаимосвязи**:\n",
    "\n",
    "Если $r_{x y} = 0$, то $b_1 = 0, \\, b_0 = \\bar{y}$, а тогда $\\hat{y} = \\bar{y}$. Т.о. нулевая гипотеза для генеральной совокупности: исследуемые переменные не связаны, а наблюдаемая корреляция случайна.\n",
    "\n",
    "$H_0: \\; \\beta_1 = 0, \\quad t = \\dfrac{b_1}{se}, \\quad df = N - 2$.\n",
    "\n",
    "**Коэффициент детерминации** — часть изменчивости (дисперсии) переменной, которая обусловленна её линейной взаимосвязью с другой переменной ($R^2 \\in [0, 1]$).\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\dfrac{SS_{res}}{SS_{total}} = 1 - \\dfrac{\\sum_i \\left( y_i - \\hat{y_i} \\right)^2}{\\sum_i \\left( y_i - \\bar{y} \\right)^2} \\,.\n",
    "$$\n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"data/R2.PNG\" width=\"500\" title=\"coefficient of determination\"></p>\n",
    "\n",
    "**Условия применимости линейной регрессии**:\n",
    "\n",
    "1. Линейная взаимосвязь переменных.\n",
    "\n",
    "2. Нормальное распределение ошибок (residuals).\n",
    "\n",
    "    <p style=\"text-align:center;\"><img src=\"data/lin_reg1.PNG\" width=\"650\" title=\"reg1\"></p>\n",
    "\n",
    "3. Гомоскедастичность ошибок (постоянный уровень изменчивости для всех значений независимой переменной). Пример нарушения (https://gallery.shinyapps.io/slr_diag/):\n",
    "\n",
    "    <p style=\"text-align:center;\"><img src=\"data/lin_reg2.PNG\" width=\"650\" title=\"reg1\"></p>\n",
    "\n",
    "**Пример**:\n",
    "\n",
    "Связь уровней бедности и образования в штатах США.\n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"data/Mathematica 03.PNG\" width=\"800\" title=\"Mathematica 03\"></p>\n",
    "\n",
    "Получили статистически значимую отрицательную линейную связь.\n",
    "\n",
    "**Замечания**:\n",
    "\n",
    "- Экстраполяция модели за пределы её области применимости не гарантирована.\n",
    "\n",
    "- Как и в случае с корреляцией модель линейной регрессии ничего не говорит о причинно-следственной связи, т.е. разделение переменных на зависимую и независимую условно.\n",
    "\n",
    "### 3.3. Регрессионный анализ с несколькими независимыми переменными\n",
    "\n",
    "Идея аналогична одномерному случаю, только теперь несколько независимых переменных (и, соответственно, уравнение линейной регрессии и МНК определяют уже не прямую, а $n$-мерную плоскость, где $n$ — число независимых переменных).\n",
    "\n",
    "$$\n",
    "\\hat{y} = b_0 + b_1 \\,x_1 + b_2 \\,x_2 + \\ldots + b_n \\,x_n \\,.\n",
    "$$\n",
    "\n",
    "**Требования к данным**:\n",
    "\n",
    "1. Линейная взаимосвязь переменных.\n",
    "2. Нормальное распределение ошибок (residuals).\n",
    "3. Гомоскедастичность ошибок.\n",
    "4. Отсутствие мультиколлинеарности.\n",
    "5. Нормальное распределение переменных (желательно).\n",
    "\n",
    "Многомерный регрессионный анализ позволяет улучшить модель, исключив фактор **влияния третьей переменной** (например, уровень знаний школьников скоррелирован с их размером обуви только из-за наличия третьей переменной — возраста школьников; т.е. если учесть в модели возраст, то корреляция между первыми двумя переменными исчезнет). Т.о. многомерный анализ лучше одномерного тем, что показывает взаимосвязь между переменными, учитывая их сразу все.\n",
    "\n",
    "При оценке коэффициента детерминации $R^2$ теперь следует делать поправку на множественные сравнения (**исправленный** $R^2$).\n",
    "\n",
    "**Пример**:\n",
    "\n",
    "Проверка наличия взаимосвязи уровня бедности в штатах США c разными социальными факторами.\n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"data/Mathematica 04.PNG\" width=\"800\" title=\"Mathematica 04\"></p>\n",
    "\n",
    "Получили статистически значимую связь бедности с факторами образования и населения столичного региона штата. Т.о. получили ещё одну независимую переменную, которая скоррелирована с зависимой, т.е. улучшили модель ($R^2$ увеличился).\n",
    "\n",
    "\n",
    "### 3.4. Выбор наилучшей модели\n",
    "\n",
    "**Мультиколлинеарность** — сильная взаимосвязь между какими-то независимыми переменными (т.е. две разные переменные по сути отражают один и тот же признак).\n",
    "\n",
    "Наличие мультиколлинеарности между какими-то независимыми переменными негативно сказывается на модели. Т.е. максимальное количество переменных $\\neq$ наилучшая возможная модель.\n",
    "\n",
    "**Алгоритм подбора оптимальной модели**:\n",
    "\n",
    "1. Построить модель множественной линейной регрессии.\n",
    "\n",
    "2. Проверить все переменные на попарные корреляции между друг другом (проверка на мультиколлинеарность).\n",
    "\n",
    "    <p style=\"text-align:center;\"><img src=\"data/multicol.PNG\" width=\"700\" title=\"multicol\"></p>\n",
    "\n",
    "    В данном примере переменная female_house сильно скоррелирована с другими независимыми, от неё и избавляемся.\n",
    "\n",
    "3. Исключить независимые переменные, не прошедшие тест.\n",
    "\n",
    "4. Из новой модели по очереди удаляем по одной переменной и считаем для каждого случая $R^2$. Если результат увеличивается, то модель лучше и выбираем её.\n",
    "\n",
    "    <p style=\"text-align:center;\"><img src=\"data/model.PNG\" width=\"550\" title=\"model\"></p>\n",
    "\n",
    "    Получается, что лучшая модель это $poverty = f(grad, white, metro)$. Для неё значение $R^2$ максимально. При этом оказалось, что исключение переменной female_house сделало статистически значимой связь между poverty и white.\n",
    "\n",
    "    <p style=\"text-align:center;\"><img src=\"data/res.PNG\" width=\"550\" title=\"res\"></p>\n",
    "\n",
    "Дополнительные темы:\n",
    "\n",
    "- кластерный анализ\n",
    "- логистическая регрессия\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
